{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### CSML1020 Course Project - New Plant Diseases Dectection\n#### Authors (Group 3): Paul Doucet, Jerry Khidaroo"},{"metadata":{},"cell_type":"markdown","source":"#### Initilization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# import seaborn as sns\nimport os","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use this to disable GPU\ntf.config.set_visible_devices([], 'GPU')","execution_count":16,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nimport keras\nfrom sklearn.model_selection import train_test_split\nfrom keras import backend\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.layers import Dropout\nfrom keras.layers.normalization import BatchNormalization","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Importing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image Data Folders\n# dataDirTrain = '../NewPlantDiseasesDatasetSample/train'\n# dataDirValidate = '../NewPlantDiseasesDatasetSample/valid'\n# dataDirTest = '../NewPlantDiseasesDatasetSample/test'\n\n#dataDirTrain = '../NewPlantDiseasesDataset/train'\n#dataDirValidate = '../NewPlantDiseasesDataset/valid'\n#dataDirTest = '../NewPlantDiseasesDataset/test'\n\n# From Kaggle Site\ndataDirTrain = '../input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/train'\ndataDirValidate = '../input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/valid'\ndataDirTest = '../input/newplantdiseasessample/NewPlantDiseasesDatasetSample/test'\n\n","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Load Train Image Data with Best Augmentation Filters"},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, fill_mode='nearest')\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\n# batch_size = 128\nbatch_size = 48\ntraining_set = train_datagen.flow_from_directory(dataDirTrain, target_size=(224, 224), batch_size=batch_size, class_mode='categorical')\nvalid_set = valid_datagen.flow_from_directory(dataDirValidate, target_size=(224, 224), batch_size=batch_size, class_mode='categorical')\n\ntrain_num = training_set.samples\nvalid_num = valid_set.samples","execution_count":19,"outputs":[{"output_type":"stream","text":"Found 70295 images belonging to 38 classes.\nFound 17572 images belonging to 38 classes.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Perform Hyper-Parameter Tuning on Selected Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.applications.vgg16 import VGG16\nimport keras\n\ndef create_model_VGG16(activation='softmax', learning_rate=0.01):\n    base_model=VGG16(include_top=False,input_shape=(224,224,3))\n    # base_model=VGG16(include_top=False,input_shape=(112,112,3))\n    base_model.trainable=False\n\n    classifier=keras.models.Sequential()\n    classifier.add(base_model)\n    classifier.add(Flatten())\n    #classifier.add(Dense(38,activation='softmax'))\n    classifier.add(Dense(38,activation=activation))\n\n    opt = Adam(lr=learning_rate)\n    \n    #classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    classifier.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return classifier","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import optimizers\n\ndef create_model_alexnet(activation='softmax', learning_rate=0.01):\n    # Initializing the CNN\n    classifier = Sequential()\n\n    # Convolution Step 1\n    classifier.add(Convolution2D(96, 11, strides = (4, 4), padding = 'valid', input_shape=(224, 224, 3), activation = 'relu'))\n\n    # Max Pooling Step 1\n    classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n    classifier.add(BatchNormalization())\n\n    # Convolution Step 2\n    classifier.add(Convolution2D(256, 11, strides = (1, 1), padding='valid', activation = 'relu'))\n\n    # Max Pooling Step 2\n    classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding='valid'))\n    classifier.add(BatchNormalization())\n\n    # Convolution Step 3\n    classifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n    classifier.add(BatchNormalization())\n\n    # Convolution Step 4\n    classifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n    classifier.add(BatchNormalization())\n\n    # Convolution Step 5\n    classifier.add(Convolution2D(256, 3, strides=(1,1), padding='valid', activation = 'relu'))\n\n    # Max Pooling Step 3\n    classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n    classifier.add(BatchNormalization())\n\n    # Flattening Step\n    classifier.add(Flatten())\n\n    # Full Connection Step\n    classifier.add(Dense(units = 4096, activation = 'relu'))\n    classifier.add(Dropout(0.4))\n    classifier.add(BatchNormalization())\n    classifier.add(Dense(units = 4096, activation = 'relu'))\n    classifier.add(Dropout(0.4))\n    classifier.add(BatchNormalization())\n    classifier.add(Dense(units = 1000, activation = 'relu'))\n    classifier.add(Dropout(0.2))\n    classifier.add(BatchNormalization())\n    classifier.add(Dense(units = 38, activation = activation))\n\n    classifier.load_weights('../input/bestweights9/best_weights_9.hdf5')\n\n    # we chose to train the top 2 conv blocks, i.e. we will freeze\n    # the first 8 layers and unfreeze the rest:\n    for i, layer in enumerate(classifier.layers[:20]):\n        layer.trainable = False\n\n    # Compiling the Model\n    classifier.compile(optimizer=optimizers.SGD(lr=learning_rate, momentum=0.9, decay=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n   \n    return classifier","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_D(activation='softmax', learning_rate=0.01):\n    classifier = Sequential()\n    classifier.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n    classifier.add(MaxPooling2D((2, 2)))\n    classifier.add(Dropout(0.2))\n    classifier.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n    classifier.add(MaxPooling2D((2, 2)))\n    classifier.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n    classifier.add(MaxPooling2D((2, 2)))\n    classifier.add(Flatten())\n    classifier.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    classifier.add(Dense(38,activation=activation))\n    \n    opt = Adam(lr=learning_rate)\n    classifier.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return classifier","execution_count":22,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, KFold, cross_val_score\nfrom keras import regularizers\n\n# Create a KerasClassifier\nmodel = KerasRegressor(build_fn = create_model_VGG16, verbose = 0)\n\n# Define the parameters to try out\nparams = {'activation': [\"softmax\"],\n          'batch_size': [32, 48, 64], \n          'epochs': [3, 5, 10],\n          'learning_rate': [0.01, 0.001, 0.0001]}\n\n# Create a randomize search cv object passing in the parameters to try\nrandom_search = RandomizedSearchCV(model,\n                                   param_distributions = params,\n                                   cv = KFold(3),\n                                   verbose=2)\n\nX_train, y_train = next(training_set)\n\nrandom_search_results = random_search.fit(X_train, y_train)\n\n# Print best score and parameters\nprint(\"Best Score: \", random_search_results.best_score_, \"and Best Params: \", random_search_results.best_params_)","execution_count":10,"outputs":[{"output_type":"stream","text":"Fitting 3 folds for each of 10 candidates, totalling 30 fits\n[CV] learning_rate=0.01, epochs=3, batch_size=32, activation=softmax .\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 1s 0us/step\n[CV]  learning_rate=0.01, epochs=3, batch_size=32, activation=softmax, total=  24.7s\n[CV] learning_rate=0.01, epochs=3, batch_size=32, activation=softmax .\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.7s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV]  learning_rate=0.01, epochs=3, batch_size=32, activation=softmax, total=  21.4s\n[CV] learning_rate=0.01, epochs=3, batch_size=32, activation=softmax .\n[CV]  learning_rate=0.01, epochs=3, batch_size=32, activation=softmax, total=  21.2s\n[CV] learning_rate=0.01, epochs=10, batch_size=64, activation=softmax \n[CV]  learning_rate=0.01, epochs=10, batch_size=64, activation=softmax, total= 1.1min\n[CV] learning_rate=0.01, epochs=10, batch_size=64, activation=softmax \n[CV]  learning_rate=0.01, epochs=10, batch_size=64, activation=softmax, total= 1.0min\n[CV] learning_rate=0.01, epochs=10, batch_size=64, activation=softmax \n[CV]  learning_rate=0.01, epochs=10, batch_size=64, activation=softmax, total= 1.0min\n[CV] learning_rate=0.001, epochs=10, batch_size=64, activation=softmax \n[CV]  learning_rate=0.001, epochs=10, batch_size=64, activation=softmax, total= 1.0min\n[CV] learning_rate=0.001, epochs=10, batch_size=64, activation=softmax \n[CV]  learning_rate=0.001, epochs=10, batch_size=64, activation=softmax, total= 1.0min\n[CV] learning_rate=0.001, epochs=10, batch_size=64, activation=softmax \n[CV]  learning_rate=0.001, epochs=10, batch_size=64, activation=softmax, total= 1.0min\n[CV] learning_rate=0.0001, epochs=10, batch_size=32, activation=softmax \n[CV]  learning_rate=0.0001, epochs=10, batch_size=32, activation=softmax, total= 1.0min\n[CV] learning_rate=0.0001, epochs=10, batch_size=32, activation=softmax \n[CV]  learning_rate=0.0001, epochs=10, batch_size=32, activation=softmax, total= 1.0min\n[CV] learning_rate=0.0001, epochs=10, batch_size=32, activation=softmax \n[CV]  learning_rate=0.0001, epochs=10, batch_size=32, activation=softmax, total= 1.0min\n[CV] learning_rate=0.0001, epochs=3, batch_size=32, activation=softmax \n[CV]  learning_rate=0.0001, epochs=3, batch_size=32, activation=softmax, total=  21.3s\n[CV] learning_rate=0.0001, epochs=3, batch_size=32, activation=softmax \n[CV]  learning_rate=0.0001, epochs=3, batch_size=32, activation=softmax, total=  21.1s\n[CV] learning_rate=0.0001, epochs=3, batch_size=32, activation=softmax \n[CV]  learning_rate=0.0001, epochs=3, batch_size=32, activation=softmax, total=  21.9s\n[CV] learning_rate=0.0001, epochs=5, batch_size=48, activation=softmax \n[CV]  learning_rate=0.0001, epochs=5, batch_size=48, activation=softmax, total=  32.9s\n[CV] learning_rate=0.0001, epochs=5, batch_size=48, activation=softmax \n[CV]  learning_rate=0.0001, epochs=5, batch_size=48, activation=softmax, total=  33.9s\n[CV] learning_rate=0.0001, epochs=5, batch_size=48, activation=softmax \n[CV]  learning_rate=0.0001, epochs=5, batch_size=48, activation=softmax, total=  32.7s\n[CV] learning_rate=0.001, epochs=3, batch_size=32, activation=softmax \n[CV]  learning_rate=0.001, epochs=3, batch_size=32, activation=softmax, total=  22.1s\n[CV] learning_rate=0.001, epochs=3, batch_size=32, activation=softmax \n[CV]  learning_rate=0.001, epochs=3, batch_size=32, activation=softmax, total=  21.3s\n[CV] learning_rate=0.001, epochs=3, batch_size=32, activation=softmax \n[CV]  learning_rate=0.001, epochs=3, batch_size=32, activation=softmax, total=  21.7s\n[CV] learning_rate=0.0001, epochs=10, batch_size=48, activation=softmax \n[CV]  learning_rate=0.0001, epochs=10, batch_size=48, activation=softmax, total= 1.0min\n[CV] learning_rate=0.0001, epochs=10, batch_size=48, activation=softmax \n[CV]  learning_rate=0.0001, epochs=10, batch_size=48, activation=softmax, total= 1.0min\n[CV] learning_rate=0.0001, epochs=10, batch_size=48, activation=softmax \n[CV]  learning_rate=0.0001, epochs=10, batch_size=48, activation=softmax, total= 1.0min\n[CV] learning_rate=0.0001, epochs=10, batch_size=64, activation=softmax \n[CV]  learning_rate=0.0001, epochs=10, batch_size=64, activation=softmax, total= 1.0min\n[CV] learning_rate=0.0001, epochs=10, batch_size=64, activation=softmax \n[CV]  learning_rate=0.0001, epochs=10, batch_size=64, activation=softmax, total= 1.0min\n[CV] learning_rate=0.0001, epochs=10, batch_size=64, activation=softmax \n[CV]  learning_rate=0.0001, epochs=10, batch_size=64, activation=softmax, total= 1.0min\n[CV] learning_rate=0.01, epochs=10, batch_size=48, activation=softmax \n[CV]  learning_rate=0.01, epochs=10, batch_size=48, activation=softmax, total= 1.0min\n[CV] learning_rate=0.01, epochs=10, batch_size=48, activation=softmax \n[CV]  learning_rate=0.01, epochs=10, batch_size=48, activation=softmax, total= 1.0min\n[CV] learning_rate=0.01, epochs=10, batch_size=48, activation=softmax \n[CV]  learning_rate=0.01, epochs=10, batch_size=48, activation=softmax, total= 1.0min\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 23.5min finished\n","name":"stderr"},{"output_type":"stream","text":"Best Score:  -3.841557343800863 and Best Params:  {'learning_rate': 0.0001, 'epochs': 3, 'batch_size': 32, 'activation': 'softmax'}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, KFold, cross_val_score\nfrom keras import regularizers\n\nfrom keras.callbacks import ModelCheckpoint\n\n# checkpoint for Alexnet Model\n#weightpath = \"../input/bestweights9/best_weights_9.hdf5\"\n#checkpoint = ModelCheckpoint(weightpath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n#callbacks_list = [checkpoint]# checkpoint\n\n\n# Create a KerasClassifier\nmodel = KerasRegressor(build_fn = create_model_alexnet, verbose = 0)\n\n# Define the parameters to try out\nparams = {'activation': [\"softmax\"],\n          'batch_size': [32, 48, 64], \n          'epochs': [3, 5, 10],\n          'learning_rate': [0.01, 0.001, 0.0001]}\n\n# Create a randomize search cv object passing in the parameters to try\nrandom_search = RandomizedSearchCV(model,\n                                   param_distributions = params,\n                                   cv = KFold(3),\n                                   verbose=1)\n\nX_train, y_train = next(training_set)\n\nrandom_search_results = random_search.fit(X_train, y_train)\n\n# Print best score and parameters\nprint(\"Best Score: \", random_search_results.best_score_, \"and Best Params: \", random_search_results.best_params_)","execution_count":24,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-24-f4fd04898dcb>, line 25)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-f4fd04898dcb>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    random_search = RandomizedSearchCV(model,\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, KFold, cross_val_score\nfrom keras import regularizers\n\n# Create a KerasClassifier\nmodel = KerasRegressor(build_fn = create_model_D, verbose = 0)\n\n# Define the parameters to try out\nparams = {'activation': [\"softmax\"],\n          'batch_size': [32, 48, 64], \n          'epochs': [3, 5, 10],\n          'learning_rate': [0.01, 0.001, 0.0001]}\n\n# Create a randomize search cv object passing in the parameters to try\nrandom_search = RandomizedSearchCV(model,\n                                   param_distributions = params,\n                                   cv = KFold(3))\n\nX_train, y_train = next(training_set)\n\nrandom_search_results = random_search.fit(X_train, y_train)\n\n# Print best score and parameters\nprint(\"Best Score: \", random_search_results.best_score_, \"and Best Params: \", random_search_results.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":false},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_score\nfrom keras.optimizers import Adam\nfrom keras import regularizers\n\n# Create a KerasClassifier\nmodel = KerasRegressor(build_fn = create_model, verbose = 0)\n\n# Define the parameters to try out\nparams = {'activation': [\"softmax\"],\n          'batch_size': [32, 48, 64], \n          'epochs': [3, 5, 10],\n          'learning_rate': [0.01, 0.001, 0.0001]}\n\n# Create a grid search cv object passing in the parameters to try\nrandom_search = GridSearchCV(model, params, cv = KFold(3))\n\nX_train, y_train = next(training_set)\n\ngrid_search_results = random_search.fit(X_train, y_train)\n\n# Print best score and parameters\nprint(\"Best Score: \", grid_search_results.best_score_, \"and Best Params: \", grid_search_results.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Inference"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}