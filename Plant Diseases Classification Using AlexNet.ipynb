{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Sample From Kaggle\n",
    "### Samir Bhattarai\n",
    "### https://www.kaggle.com/vipoooool/plant-diseases-classification-using-alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data to Notebook Instance \n",
    "### NOTE: Run these commands from the Terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data to Notebook Instance \n",
    "### NOTE: Run these commands from the Terminal\n",
    "\n",
    "## Run the following commands on the Terminal\n",
    "##### pip install kaggle\n",
    "## Create kaggle directory \n",
    "##### mkdir /home/jupyter/.kaggle\n",
    "##### cp kaggle.json /home/jupyter/.kaggle\n",
    "##### kaggle competitions list\n",
    "##### kaggle datasets download -d vipoooool/new-plant-diseases-dataset\n",
    "##### unzip 'new-plant-diseases-dataset.zip'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/jupyter/.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir /home/jupyter/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp kaggle.json /home/jupyter/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                               deadline             category            reward  teamCount  userHasEntered  \n",
      "------------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
      "tpu-getting-started                               2030-06-03 23:59:00  Getting Started      Kudos         98           False  \n",
      "digit-recognizer                                  2030-01-01 00:00:00  Getting Started  Knowledge       3109           False  \n",
      "titanic                                           2030-01-01 00:00:00  Getting Started  Knowledge      23342           False  \n",
      "house-prices-advanced-regression-techniques       2030-01-01 00:00:00  Getting Started  Knowledge       5184           False  \n",
      "connectx                                          2030-01-01 00:00:00  Getting Started  Knowledge        599           False  \n",
      "nlp-getting-started                               2030-01-01 00:00:00  Getting Started      Kudos       1538           False  \n",
      "competitive-data-science-predict-future-sales     2020-12-31 23:59:00  Playground           Kudos       7547           False  \n",
      "halite                                            2020-09-15 23:59:00  Featured              Swag        440           False  \n",
      "birdsong-recognition                              2020-09-15 23:59:00  Research           $25,000        179           False  \n",
      "siim-isic-melanoma-classification                 2020-08-17 23:59:00  Featured           $30,000       1430           False  \n",
      "global-wheat-detection                            2020-08-04 23:59:00  Research           $15,000       1184           False  \n",
      "open-images-object-detection-rvc-2020             2020-07-31 16:00:00  Playground       Knowledge         41           False  \n",
      "open-images-instance-segmentation-rvc-2020        2020-07-31 16:00:00  Playground       Knowledge          9           False  \n",
      "hashcode-photo-slideshow                          2020-07-27 23:59:00  Playground       Knowledge         46           False  \n",
      "prostate-cancer-grade-assessment                  2020-07-22 23:59:00  Featured           $25,000        683           False  \n",
      "alaska2-image-steganalysis                        2020-07-20 23:59:00  Research           $25,000        730           False  \n",
      "m5-forecasting-accuracy                           2020-06-30 23:59:00  Featured           $50,000       5445           False  \n",
      "m5-forecasting-uncertainty                        2020-06-30 23:59:00  Featured           $50,000        827           False  \n",
      "trends-assessment-prediction                      2020-06-29 23:59:00  Research           $25,000       1037            True  \n",
      "jigsaw-multilingual-toxic-comment-classification  2020-06-22 23:59:00  Featured           $50,000       1621           False  \n"
     ]
    }
   ],
   "source": [
    "! kaggle competitions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new-plant-diseases-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d vipoooool/new-plant-diseases-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide Kaggle API key from other users on this system\n",
    "! chmod 600 /home/jupyter/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNetModel.hdf5', 'best_weights_9.hdf5']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/home/jupyter/input/plant-diseases-classification-using-alexnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN Based On AlexNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 38)                38038     \n",
      "=================================================================\n",
      "Total params: 28,117,790\n",
      "Trainable params: 28,096,654\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Importing Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Convolution Step 1\n",
    "classifier.add(Convolution2D(96, 11, strides = (4, 4), padding = 'valid', input_shape=(224, 224, 3), activation = 'relu'))\n",
    "\n",
    "# Max Pooling Step 1\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Convolution Step 2\n",
    "classifier.add(Convolution2D(256, 11, strides = (1, 1), padding='valid', activation = 'relu'))\n",
    "\n",
    "# Max Pooling Step 2\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding='valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Convolution Step 3\n",
    "classifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Convolution Step 4\n",
    "classifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Convolution Step 5\n",
    "classifier.add(Convolution2D(256, 3, strides=(1,1), padding='valid', activation = 'relu'))\n",
    "\n",
    "# Max Pooling Step 3\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Flattening Step\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Full Connection Step\n",
    "classifier.add(Dense(units = 4096, activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(units = 4096, activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(units = 1000, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(units = 38, activation = 'softmax'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Weights To The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_weights('/home/jupyter/input/plant-diseases-classification-using-alexnet/best_weights_9.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning By Freezing Some Layers Of Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv2d_1\n",
      "1 max_pooling2d_1\n",
      "2 batch_normalization_1\n",
      "3 conv2d_2\n",
      "4 max_pooling2d_2\n",
      "5 batch_normalization_2\n",
      "6 conv2d_3\n",
      "7 batch_normalization_3\n",
      "8 conv2d_4\n",
      "9 batch_normalization_4\n",
      "10 conv2d_5\n",
      "11 max_pooling2d_3\n",
      "12 batch_normalization_5\n",
      "13 flatten_1\n",
      "14 dense_1\n",
      "15 dropout_1\n",
      "16 batch_normalization_6\n",
      "17 dense_2\n",
      "18 dropout_2\n",
      "19 batch_normalization_7\n",
      "20 dense_3\n",
      "21 dropout_3\n",
      "22 batch_normalization_8\n",
      "23 dense_4\n"
     ]
    }
   ],
   "source": [
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "from keras import layers\n",
    "for i, layer in enumerate(classifier.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezed layers:\n",
      "0 conv2d_1035\n",
      "1 max_pooling2d_45\n",
      "2 batch_normalization_1035\n",
      "3 conv2d_1036\n",
      "4 max_pooling2d_46\n",
      "5 batch_normalization_1036\n",
      "6 conv2d_1037\n",
      "7 batch_normalization_1037\n",
      "8 conv2d_1038\n",
      "9 batch_normalization_1038\n",
      "10 conv2d_1039\n",
      "11 max_pooling2d_47\n",
      "12 batch_normalization_1039\n",
      "13 flatten_1\n",
      "14 dense_4\n",
      "15 dropout_5\n",
      "16 batch_normalization_1040\n",
      "17 dense_5\n",
      "18 dropout_6\n",
      "19 batch_normalization_1041\n"
     ]
    }
   ],
   "source": [
    "# we chose to train the top 2 conv blocks, i.e. we will freeze\n",
    "# the first 8 layers and unfreeze the rest:\n",
    "print(\"Freezed layers:\")\n",
    "for i, layer in enumerate(classifier.layers[:20]):\n",
    "    print(i, layer.name)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary After Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 38)                38038     \n",
      "=================================================================\n",
      "Total params: 28,117,790\n",
      "Trainable params: 28,096,654\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#trainable parameters decrease after freezing some bottom layers   \n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Model\n",
    "from keras import optimizers\n",
    "classifier.compile(optimizer=optimizers.SGD(lr=0.001, momentum=0.9, decay=0.005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70297 images belonging to 38 classes.\n",
      "Found 17572 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "# image preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 128\n",
    "base_dir = \"/home/jupyter/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(base_dir+'/train',\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "valid_set = valid_datagen.flow_from_directory(base_dir+'/valid',\n",
    "                                            target_size=(224, 224),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3, 'Blueberry___healthy': 4, 'Cherry_(including_sour)___Powdery_mildew': 5, 'Cherry_(including_sour)___healthy': 6, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7, 'Corn_(maize)___Common_rust_': 8, 'Corn_(maize)___Northern_Leaf_Blight': 9, 'Corn_(maize)___healthy': 10, 'Grape___Black_rot': 11, 'Grape___Esca_(Black_Measles)': 12, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13, 'Grape___healthy': 14, 'Orange___Haunglongbing_(Citrus_greening)': 15, 'Peach___Bacterial_spot': 16, 'Peach___healthy': 17, 'Pepper,_bell___Bacterial_spot': 18, 'Pepper,_bell___healthy': 19, 'Potato___Early_blight': 20, 'Potato___Late_blight': 21, 'Potato___healthy': 22, 'Raspberry___healthy': 23, 'Soybean___healthy': 24, 'Squash___Powdery_mildew': 25, 'Strawberry___Leaf_scorch': 26, 'Strawberry___healthy': 27, 'Tomato___Bacterial_spot': 28, 'Tomato___Early_blight': 29, 'Tomato___Late_blight': 30, 'Tomato___Leaf_Mold': 31, 'Tomato___Septoria_leaf_spot': 32, 'Tomato___Spider_mites Two-spotted_spider_mite': 33, 'Tomato___Target_Spot': 34, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35, 'Tomato___Tomato_mosaic_virus': 36, 'Tomato___healthy': 37}\n"
     ]
    }
   ],
   "source": [
    "class_dict = training_set.class_indices\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "li = list(class_dict.keys())\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = training_set.samples\n",
    "valid_num = valid_set.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 67/549 [==>...........................] - ETA: 1:14:04 - loss: 0.0934 - accuracy: 0.9691"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-15acfb157e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                          \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_num\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                          callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#saving model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AlexNetModel.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "weightpath = \"best_weights_9.hdf5\"\n",
    "checkpoint = ModelCheckpoint(weightpath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#fitting images to CNN\n",
    "history = classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch=train_num//batch_size,\n",
    "                         validation_data=valid_set,\n",
    "                         epochs=1,\n",
    "                         validation_steps=valid_num//batch_size,\n",
    "                         callbacks=callbacks_list)\n",
    "#saving model\n",
    "filepath=\"AlexNetModel.hdf5\"\n",
    "classifier.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting training values\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "#accuracy plot\n",
    "plt.plot(epochs, acc, color='green', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "#loss plot\n",
    "plt.plot(epochs, loss, color='pink', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, color='red', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting an image\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "image_path = \"/home/jupyter/test/test/AppleCedarRust1.JPG\"\n",
    "new_img = image.load_img(image_path, target_size=(224, 224))\n",
    "img = image.img_to_array(new_img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img/255\n",
    "\n",
    "print(\"Following is our prediction:\")\n",
    "prediction = classifier.predict(img)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "d = prediction.flatten()\n",
    "j = d.max()\n",
    "for index,item in enumerate(d):\n",
    "    if item == j:\n",
    "        class_name = li[index]\n",
    "\n",
    "##Another way\n",
    "# img_class = classifier.predict_classes(img)\n",
    "# img_prob = classifier.predict_proba(img)\n",
    "# print(img_class ,img_prob )\n",
    "\n",
    "\n",
    "#ploting image with predicted class name        \n",
    "plt.figure(figsize = (4,4))\n",
    "plt.imshow(new_img)\n",
    "plt.axis('off')\n",
    "plt.title(class_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
